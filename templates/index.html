<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Mask Wearing Detection — Single Page</title>
  <style>
    :root{
      --bg:#0f1724; /* dark blue-gray */
      --card:#0b1220;
      --accent:#16a34a; /* green */
      --muted:#94a3b8;
      --glass: rgba(255,255,255,0.03);
      font-family: Inter, ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial;
    }
    *{box-sizing:border-box}
    body{
      margin:0;min-height:100vh;background:linear-gradient(180deg,#071022 0%, var(--bg) 100%);color:#e6eef8;display:flex;align-items:center;justify-content:center;padding:32px;
    }
    .container{
      width:100%;max-width:980px;background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));border-radius:14px;padding:20px;box-shadow:0 10px 30px rgba(2,6,23,0.6);
      display:grid;grid-template-columns:440px 1fr;gap:18px;align-items:start
    }

    .card{background:var(--card);padding:16px;border-radius:12px;box-shadow:0 6px 18px rgba(2,6,23,0.5);}

    header{display:flex;gap:12px;align-items:center;margin-bottom:8px}
    .logo{width:48px;height:48px;border-radius:10px;background:linear-gradient(135deg,#0ea5a9,#7c3aed);display:flex;align-items:center;justify-content:center;font-weight:700}
    h1{font-size:18px;margin:0}
    p.lead{color:var(--muted);margin:6px 0 14px;font-size:13px}

    video#video{width:100%;height:280px;background:#000;border-radius:10px;object-fit:cover}
    canvas#overlay{position:absolute;left:0;top:0}

    .controls{display:flex;gap:8px;margin-top:12px}
    button{background:linear-gradient(180deg,#111827,#0b1220);border:1px solid rgba(255,255,255,0.04);color:#e6eef8;padding:10px 12px;border-radius:10px;cursor:pointer;font-weight:600}
    button.primary{background:linear-gradient(180deg,#10b981,#059669);border:none;color:#042;}
    button.ghost{background:transparent;border:1px dashed rgba(255,255,255,0.06);}

    .status{margin-top:12px;padding:10px;border-radius:10px;background:var(--glass);font-size:14px;color:var(--muted)}

    .right{display:flex;flex-direction:column;gap:12px}
    .info{padding:12px;border-radius:10px;background:linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));}
    .result{padding:18px;border-radius:12px;text-align:center}
    .badge{display:inline-block;padding:8px 12px;border-radius:999px;font-weight:700}
    .mask{background:rgba(16,185,129,0.12);color:#10b981;border:1px solid rgba(16,185,129,0.18)}
    .nomask{background:rgba(239,68,68,0.08);color:#ef4444;border:1px solid rgba(239,68,68,0.12)}

    .notes{font-size:13px;color:var(--muted);line-height:1.5}

    footer{grid-column:1/-1;margin-top:12px;text-align:center;color:var(--muted);font-size:13px}

    /* responsive */
    @media (max-width:900px){
      .container{grid-template-columns:1fr;}
      video#video{height:260px}
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="card">
      <header>
        <div class="logo">MW</div>
        <div>
          <h1>Mask Wearing Detection</h1>
          <p class="lead">Single-page demo — webcam + simple client-side detection heuristic. Replace the detection function with your ML model for production.</p>
        </div>
      </header>

      <div style="position:relative">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay" width="640" height="480" style="position:absolute;top:0;left:0;pointer-events:none"></canvas>
      </div>

      <div class="controls">
        <button id="startBtn" class="primary">Start Camera</button>
        <button id="snapBtn" class="ghost">Detect Now</button>
        <button id="stopBtn">Stop</button>
      </div>

      <div class="status" id="status">Status: Idle</div>
    </div>

    <div class="right">
      <div class="info card">
        <div class="result" id="resultBox">
          <div style="font-size:13px;color:var(--muted)">Detection result</div>
          <div id="label" style="margin-top:10px;font-size:20px;font-weight:800">—</div>
          <div id="confidence" style="margin-top:8px;color:var(--muted)"></div>
        </div>
      </div>

      <div class="info card">
        <h3 style="margin:0 0 10px 0">How this demo works</h3>
        <p class="notes">This page captures your webcam frame and runs a <strong>very simple heuristic</strong> to guess whether a mask is present: it crops the lower face area and checks color/texture cues such as dominant blue-ish color (disposable masks). <strong>Not reliable</strong> — replace with a real model for production (TensorFlow.js, ONNX, or server-side inference).</p>
        <ul class="notes">
          <li>Works best with a plain colored mask (blue/white) facing the camera.</li>
          <li>Privacy: video frames are processed locally in the browser and not uploaded anywhere.</li>
        </ul>
      </div>

      <div class="info card">
        <h3 style="margin:0 0 10px 0">Next steps / Integration</h3>
        <p class="notes">To add a real model, you can:</p>
        <ol class="notes">
          <li>Use a TF.js model: load model.json and call <code>model.predict()</code>.</li>
          <li>Use a server-side API: POST the frame to your inference endpoint.</li>
          <li>Use MediaPipe / FaceMesh to accurately crop the lower-face region.</li>
        </ol>
      </div>
    </div>

    <footer>Made with ❤️ — Demo only. For production, integrate a validated ML model and test extensively.</footer>
  </div>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const snapBtn = document.getElementById('snapBtn');
    const status = document.getElementById('status');
    const label = document.getElementById('label');
    const confidence = document.getElementById('confidence');

    let stream = null;

    async function startCamera(){
      try{
        stream = await navigator.mediaDevices.getUserMedia({video:{ facingMode:'user', width:640, height:480 }, audio:false});
        video.srcObject = stream;
        status.textContent = 'Status: Camera started';
        startBtn.disabled = true;
      }catch(err){
        console.error(err);
        status.textContent = 'Status: Unable to access camera — ' + err.message;
      }
    }

    function stopCamera(){
      if(stream){
        stream.getTracks().forEach(t => t.stop());
        stream = null;
        video.srcObject = null;
        status.textContent = 'Status: Camera stopped';
        startBtn.disabled = false;
      }
    }

    // Very simple heuristic detector — replace with ML model for production.
    // Steps:
    // 1. capture frame
    // 2. assume face is roughly centered; crop lower-middle region
    // 3. compute average color and edge energy: blue-dominant + smooth area => mask
    function heuristicDetect(){
      const w = video.videoWidth || 640;
      const h = video.videoHeight || 480;
      overlay.width = w;
      overlay.height = h;
      ctx.drawImage(video, 0, 0, w, h);

      // draw face guide box (approx center)
      const boxW = Math.floor(w * 0.4);
      const boxH = Math.floor(h * 0.5);
      const boxX = Math.floor((w - boxW) / 2);
      const boxY = Math.floor(h * 0.25);

      // lower-face region (where mask would be)
      const lowerY = boxY + Math.floor(boxH * 0.45);
      const lowerH = Math.floor(boxH * 0.45);
      const lowerX = boxX;
      const lowerW = boxW;

      // frame rectangle
      ctx.strokeStyle = 'rgba(255,255,255,0.25)';
      ctx.lineWidth = 2;
      ctx.strokeRect(boxX, boxY, boxW, boxH);

      // lower-face rectangle
      ctx.strokeStyle = 'rgba(0,200,255,0.9)';
      ctx.lineWidth = 2;
      ctx.strokeRect(lowerX, lowerY, lowerW, lowerH);

      const imgData = ctx.getImageData(lowerX, lowerY, lowerW, lowerH);
      const data = imgData.data;
      let r=0,g=0,b=0; let edges=0; let count=0;

      // average color + simple edge energy (Sobel-like approximation)
      for(let y=0;y<lowerH;y++){
        for(let x=0;x<lowerW;x++){
          const i = (y*lowerW + x)*4;
          const rr=data[i], gg=data[i+1], bb=data[i+2];
          r += rr; g += gg; b += bb; count++;

          // simple gradient magnitude approximation (horizontal differences)
          if(x>0){
            const j = (y*lowerW + (x-1))*4;
            const gr = Math.abs(rr - data[j]);
            const ggdiff = Math.abs(gg - data[j+1]);
            const gbdiff = Math.abs(bb - data[j+2]);
            edges += (gr + ggdiff + gbdiff)/3;
          }
        }
      }
      r/=count; g/=count; b/=count;
      edges/=count;

      // heuristic rules (tweak as needed):
      // - mask often has higher blue channel (for blue/white masks)
      // - mask area is comparatively smoother (lower edge energy)
      const blueRatio = b / (r+g+0.0001);
      // confidence metric 0..1
      let conf = Math.min(1, Math.max(0, (blueRatio - 0.7) * 1.8 + (1 - edges/40) * 0.6));

      // fallback: if face not likely (very dark or tiny), mark unknown
      const bright = (r+g+b)/3;
      if(bright < 30 || lowerW < 20 || lowerH < 20){
        label.textContent = 'No face detected / too dark';
        confidence.textContent = '';
        return;
      }

      if(conf > 0.45){
        label.innerHTML = `<span class="badge mask">Mask detected</span>`;
        confidence.textContent = `Confidence (heuristic): ${(conf*100).toFixed(0)}%`;
      }else{
        label.innerHTML = `<span class="badge nomask">No mask detected</span>`;
        confidence.textContent = `Confidence (heuristic): ${((1-conf)*100).toFixed(0)}%`;
      }
    }

    startBtn.addEventListener('click', ()=>{
      startCamera();
    });
    stopBtn.addEventListener('click', ()=>{
      stopCamera();
    });
    snapBtn.addEventListener('click', ()=>{
      if(!stream){ status.textContent = 'Status: Camera not running'; return; }
      heuristicDetect();
    });

    // allow auto-detect every n ms when camera running (optional)
    let autoDetect = false;
    video.addEventListener('play', ()=>{
      if(autoDetect) runAutoDetect();
    });

    async function runAutoDetect(){
      while(stream && autoDetect){
        heuristicDetect();
        await new Promise(r=>setTimeout(r, 800));
      }
    }

    // keyboard shortcuts
    window.addEventListener('keydown', e=>{
      if(e.key===' '){ e.preventDefault(); heuristicDetect(); }
      if(e.key==='s'){ startCamera(); }
      if(e.key==='x'){ stopCamera(); }
    });

    // Expose where to plug a real model: in place of heuristicDetect(), load TF.js model and use model.predict on cropped image.
    // Example (pseudocode):
    // const model = await tf.loadGraphModel('model/model.json');
    // const tensor = tf.browser.fromPixels(cropped).resizeNearestNeighbor([224,224]).toFloat().expandDims(0).div(255);
    // const out = model.predict(tensor); // interpret logits/softmax

  </script>
</body>
</html>
